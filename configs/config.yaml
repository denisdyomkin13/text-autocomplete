# Конфигурация проекта

# Пути к данным
data:
  raw_data_path: "data/raw_dataset.csv"
  train_path: "data/train.csv"
  val_path: "data/val.csv"
  test_path: "data/test.csv"
  vocab_path: "data/vocab.csv"

# Параметры предобработки
preprocessing:
  language: "english"
  sample_size: 50000  # Размер выборки для обучения
  max_vocab_size: 100000
  min_word_freq: 2
  max_sequence_length: 40
  test_size: 0.2
  val_size: 0.1

# Параметры LSTM модели
lstm_model:
  embedding_dim: 256
  hidden_dim: 512
  num_layers: 2
  dropout: 0.3
  learning_rate: 0.001
  clip_grad: 1.0

# Параметры обучения
training:
  batch_size: 64
  num_epochs: 15
  save_every: 5
  early_stopping_patience: 5
  device: "cuda"  # или "cpu"

# Параметры генерации
generation:
  max_length: 20
  temperature: 0.9
  top_k: 50
  top_p: 0.95
  do_sample: true

# Параметры Transformer модели
transformer:
  model_name: "distilgpt2"
  max_new_tokens: 20
  temperature: 0.9
  top_k: 50
  top_p: 0.95
  do_sample: true

# Параметры оценки
evaluation:
  num_samples: 100
  split_ratio: 0.75  # Доля текста для промпта